{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNlJrfHT07YQ"
      },
      "outputs": [],
      "source": [
        "!pip install -q streamlit\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "geQmINYv1mvK",
        "outputId": "7f77b92b-15d0-4bbe-adbe-49ddd06a87fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUi_RTIa2CwS",
        "outputId": "fdba1983-67b5-46ae-f5de-99c5bf469cdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "\n",
        "from datetime import datetime\n",
        "from datetime import timedelta\n",
        "from dateutil.relativedelta import relativedelta\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from plotly import graph_objs as go\n",
        "\n",
        "from darts import TimeSeries\n",
        "from darts.models import RNNModel\n",
        "from darts.metrics import mape\n",
        "from darts.utils.timeseries_generation import datetime_attribute_timeseries\n",
        "from darts.models import forecasting\n",
        "from darts.dataprocessing.transformers import Scaler, MissingValuesFiller\n",
        "\n",
        "import yfinance as yf\n",
        "\n",
        "\n",
        "#Getting date from one year ago\n",
        "one_year_ago = datetime.now() - relativedelta(years=1) \n",
        "one_year_ago = one_year_ago.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "#Getting date today\n",
        "today = datetime.now()\n",
        "today = today.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "#Adding one day to the date one year ago \n",
        "one_year_ago_plus_one = datetime.now() - relativedelta(years=1) + timedelta(days=1)\n",
        "one_year_ago_plus_one = one_year_ago_plus_one.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "\n",
        "st.title('Stock Forecast App')\n",
        "\n",
        "stocks = ('AAPL', 'ACN', 'ADBE', 'ADI', 'ADSK', 'AKAM', 'AMAT', 'AMD', 'ANET', 'ANSS', 'AVGO', 'CDNS', 'CDW', 'CRM', 'CSCO', 'CTSH', 'DXC', 'ENPH', 'EPAM', 'FFIV', 'FICO', 'FSLR', 'FTNT', 'GLW', 'INTU', 'IT', 'JNPR', 'KEYS', 'KLAC', 'LRCX', 'MCHP', 'MPWR', 'MSI', 'MU', 'NOW', 'NTAP', 'NVDA', 'NXPI', 'ON', 'PTC', 'QCOM', 'QRVO', 'ROP', 'ROP', 'SEDG', 'SNPS', 'SWKS', 'TEL', 'TER', 'TRMB', 'TXN', 'TYL', 'VRSN', 'ZBRA')\n",
        "selected_stock = st.selectbox('Select the stock you wish to view/predict', stocks)\n",
        "\n",
        "def load_data_and_process(tick):\n",
        "    #Accessing YFinance\n",
        "    ticker= yf.Ticker(\"fico\")\n",
        "\n",
        "    #Getting pandas dataframe of stock data from one year ago\n",
        "    df = ticker.history(start=one_year_ago, end=today, interval=\"1d\")\n",
        "\n",
        "    idx = pd.date_range(start=one_year_ago_plus_one, end=today)\n",
        "    #Making index into Datetime index\n",
        "    df.index = pd.DatetimeIndex(df.index)\n",
        "    df.index = df.index.tz_localize(None) \n",
        "\n",
        "    #Reindexing dataframe to fill in missing dates due to stock market closing on weekends\n",
        "    df = df.reindex(idx, method = 'pad')\n",
        "\n",
        "    return df\n",
        "  \n",
        "def data_transform(df):\n",
        "    #Put dataframe into a Darts \"Timeseries\" object so that data can be fed into a Darts forecasting model. For more information on Timeseries objects, please look here: https://unit8co.github.io/darts/generated_api/darts.timeseries.html \n",
        "    series = TimeSeries.from_dataframe(df)\n",
        "\n",
        "    #Drop all columns besides \"Close\" Column\n",
        "    adj_series = series.drop_columns(['Open', 'High', 'Low', 'Volume', 'Dividends', 'Stock Splits'])\n",
        "\n",
        "    #Transform training set, validation set, and entire series to values between 0 and 1.\n",
        "    transformer = Scaler()\n",
        "\n",
        "    #train_transformed = transformer.fit_transform(training)\n",
        "    #val_transformed = transformer.transform(validation)\n",
        "\n",
        "    series_transformed = transformer.transform(adj_series)\n",
        "\n",
        "    return series_transformed\n",
        "\n",
        "def LSTM_Model(series_transformed, days):\n",
        "    my_model = RNNModel(\n",
        "    model=\"LSTM\",\n",
        "    n_rnn_layers = 3, # Number of LSTM layers\n",
        "    hidden_dim=4,\n",
        "    dropout=0.2,\n",
        "    batch_size=16,\n",
        "    n_epochs=10,\n",
        "    optimizer_kwargs={\"lr\": 1e-3}, #learning rate\n",
        "    model_name=\"Air_RNN\",\n",
        "    log_tensorboard=True,\n",
        "    random_state=42,\n",
        "    training_length=20,\n",
        "    input_chunk_length=14,\n",
        "    force_reset=True,\n",
        "    save_checkpoints=True,\n",
        "    )\n",
        "\n",
        "    #Fit model on training data\n",
        "    my_model.fit(series_transformed)\n",
        "\n",
        "    pred = my_model.predict(n=days)\n",
        "    #Perform inverse scaling on prediction\n",
        "    predicted_values = transformer.inverse_transform(pred)\n",
        "    return predicted_values\n",
        "\n",
        "def plot_predictions(predicted_values, adj_series):\n",
        "    fig = plt.plot(predicted_values)\n",
        "    fig1 = plt.plot(adj_series)\n",
        "    st.pyplot(fig1, fig)\n",
        "\n",
        "\n",
        "def inverse_transform_data(data):\n",
        "    original_series = transformer.inverse_transform(data)\n",
        "    return original_series\n",
        "\n",
        "#might not need this function\n",
        "#def forecast_values(days):\n",
        "    #pred = my_model.predict(n=days)\n",
        "    ##Perform inverse scaling on prediction\n",
        "    #predicted_values = transformer.inverse_transform(pred)\n",
        "    #return predicted_values\n",
        "\n",
        "#def plot_predictions(predicted_values, adj_series):\n",
        "    #Plot total data vs prediction\n",
        "    #adj_series.plot(label='actual')\n",
        "    #predicted_values.plot(label='forecast')\n",
        "    #plt.legend();\n",
        "    #plt.title(\"Total Data vs Inverse Scaled Prediction\")\n",
        "\n",
        "#Likely will not need this\n",
        "#def train_validation_split(adj_series):\n",
        "    #Divide dataset into training and validation/testing sets. \"Split_after\" function is a method of a Darts Timeseries object. https://unit8co.github.io/darts/generated_api/darts.timeseries.html#darts.timeseries.TimeSeries.split_after\n",
        "    #training, validation = adj_series.split_after(0.8)\n",
        "\n",
        "#def load_data(ticker):\n",
        "    #data = yf.download(ticker, START, TODAY)\n",
        "    #data.reset_index(inplace=True)\n",
        "    #return data\n",
        "\n",
        "#def transform_data(ticker):\n",
        "    #aapl= yf.Ticker(ticker)\n",
        "    #df = aapl.history(start=\"2022-04-01\", end=\"2023-04-01\", interval=\"1d\")\n",
        "    #idx = pd.date_range(start='2022-04-01', end='2023-04-01')\n",
        "    #df.index = pd.DatetimeIndex(df.index)\n",
        "    #df.index = df.index.tz_localize(None) \n",
        "    #df = df.reindex(idx, method = 'pad')\n",
        "    #series = TimeSeries.from_dataframe(df)\n",
        "    #adj_series = series.drop_columns(['Open', 'High', 'Low', 'Volume', 'Dividends', 'Stock Splits'])\n",
        "    #return adj_series\n",
        "\n",
        "data_load_state = st.text('Loading data...')\n",
        "data = load_data_and_process(selected_stock)\n",
        "data_load_state.text('Loading data... done!')\n",
        "st.subheader('Original Data From Previous Year')\n",
        "st.write(data.tail())\n",
        "\n",
        "\n",
        "transform_data_state = st.text('Transforming data...')\n",
        "transformed_data = data_transform(data)\n",
        "transform_data_state.text('Transforming data...done')\n",
        "\n",
        "predicted_values = LSTM_Model(transformed_data,60)\n",
        "\n",
        "original_series = inverse_transform_data(transformed_data)\n",
        "plot_predictions(predicted_values, original_series)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#import shutil\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "#from tqdm import tqdm_notebook as tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from darts import TimeSeries\n",
        "from darts.models import RNNModel, ExponentialSmoothing, BlockRNNModel\n",
        "from darts.metrics import mape, mse\n",
        "#from darts.utils.statistics import check_seasonality, plot_acf\n",
        "#from darts.datasets import AirPassengersDataset, SunspotsDataset\n",
        "from darts.utils.timeseries_generation import datetime_attribute_timeseries\n",
        "from darts.models import forecasting\n",
        "from darts.dataprocessing.transformers import Scaler, MissingValuesFiller\n",
        "\n",
        "import yfinance as yf\n",
        "aapl= yf.Ticker(selected_stock)\n",
        "df = aapl.history(start=\"2022-04-01\", end=\"2023-04-01\", interval=\"1d\")\n",
        "\n",
        "# data.reset_index(inplace=True)\n",
        "# data = data[['Date', 'Close']]\n",
        "\n",
        "idx = pd.date_range(start='2022-04-01', end='2023-04-01')\n",
        "df.index = pd.DatetimeIndex(df.index)\n",
        "df.index = df.index.tz_localize(None) \n",
        "# # #df['Date'] = pd.to_datetime(df['Date'])\n",
        "# # #print(df)\n",
        "# # #df.set_index='Date'\n",
        "# # #print(df)\n",
        "# # df.index = pd.DatetimeIndex(df.index)\n",
        "# # print(df)\n",
        "df = df.reindex(idx, method = 'pad')\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "NsyjYrB34Q1F",
        "outputId": "cfac1a8e-06ca-4cab-8744-94500e5c8a1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-15034f65e83b>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0myfinance\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0myf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0maapl\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0myf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTicker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected_stock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maapl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"2022-04-01\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"2023-04-01\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"1d\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'selected_stock' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "series = TimeSeries.from_dataframe(df)\n",
        "\n",
        "adj_series = series.drop_columns(['Open', 'High', 'Low', 'Volume', 'Dividends', 'Stock Splits'])\n",
        "training, validation = adj_series.split_after(0.8)\n",
        "\n",
        "from darts.dataprocessing.transformers import Scaler\n",
        "transformer = Scaler()\n",
        "train_transformed = transformer.fit_transform(training)\n",
        "val_transformed = transformer.transform(validation)\n",
        "series_transformed = transformer.transform(adj_series)\n",
        "\n"
      ],
      "metadata": {
        "id": "_Ac2UAvv5c77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_model = RNNModel(\n",
        "    model=\"LSTM\",\n",
        "    n_rnn_layers = 3,\n",
        "    hidden_dim=4,\n",
        "    dropout=0,\n",
        "    batch_size=16,\n",
        "    n_epochs=10,\n",
        "    optimizer_kwargs={\"lr\": 1e-3},\n",
        "    model_name=\"Air_RNN\",\n",
        "    log_tensorboard=True,\n",
        "    random_state=42,\n",
        "    training_length=20,\n",
        "    input_chunk_length=3,\n",
        "    force_reset=True,\n",
        "    save_checkpoints=True,\n",
        ")\n",
        "my_model.fit(train_transformed)"
      ],
      "metadata": {
        "id": "bOvS0Bmh56he"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fen6szPa2R-N",
        "outputId": "77374d78-f5ee-4141-dd16-430d15b43916"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No description\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No repository field.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No README data\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No license field.\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25h+ localtunnel@2.0.2\n",
            "updated 1 package and audited 36 packages in 1.079s\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "found \u001b[92m0\u001b[0m vulnerabilities\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!npm install localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kA9aRZ-V2Xfk"
      },
      "outputs": [],
      "source": [
        "!streamlit run /content/app.py &>/content/logs.txt &"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPXlp_hX2a96",
        "outputId": "68f03bdf-eeaf-49f6-9d6f-8062f9a3c747"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25hnpx: installed 22 in 2.461s\n",
            "your url is: https://tricky-rats-search.loca.lt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}